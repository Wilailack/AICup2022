{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ne_NAWIW17BV"
      },
      "source": [
        "## import package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I6lSNVyS9Q8Q"
      },
      "outputs": [],
      "source": [
        "!pip install torch\n",
        "!pip install pandas nltk\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X9lpgvIjcAOI"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BjcgsM7vwcc9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import CrossEntropyLoss\n",
        "import math\n",
        "import numpy as np\n",
        "import time\n",
        "import torch, pandas as pd\n",
        "import nltk\n",
        "import re\n",
        "nltk.download('punkt')\n",
        "\n",
        "from transformers import set_seed\n",
        "set_seed(123)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SYk_hc2dpscj"
      },
      "outputs": [],
      "source": [
        "# Training data file\n",
        "directory=\"/content/drive/MyDrive/Colab Notebooks/AIcup2022/\"\n",
        "\n",
        "\n",
        "file=directory+\"train.csv\"\n",
        "df=pd.read_csv(file, encoding = \"ISO-8859-1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UCLFFNNAgddv"
      },
      "outputs": [],
      "source": [
        "file=directory+\"test.csv\"\n",
        "df_test=pd.read_csv(file, encoding = \"ISO-8859-1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fnwRabH8kkAq"
      },
      "outputs": [],
      "source": [
        "df = df.drop(columns=['Unnamed: 6', 'total no.: 7987'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p5BfM2Ybgkj8"
      },
      "outputs": [],
      "source": [
        "df_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9AS30UmnnFwn"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-O0ShLN5PY5"
      },
      "source": [
        "## Data process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nAVtEjT_jnvx"
      },
      "outputs": [],
      "source": [
        "# train\n",
        "df[['q','r',\"q'\",\"r'\"]] = df[['q','r',\"q'\",\"r'\"]].apply(lambda x: x.str.strip('\\\"'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ghvxoOmdnyo"
      },
      "outputs": [],
      "source": [
        "# test\n",
        "df_test[['q','r']] = df_test[['q','r']].apply(lambda x: x.str.strip('\\\"'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1-uoUpZyyLn"
      },
      "outputs": [],
      "source": [
        "# train\n",
        "df['r'] = df['s'] + ':' + df['r']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xzf3kWXfd7jp"
      },
      "outputs": [],
      "source": [
        "# test\n",
        "df_test['r'] = df_test['s'] + ':' + df_test['r']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_uyE8vcHdx8"
      },
      "outputs": [],
      "source": [
        "# train\n",
        "df['sub_q_true'] = [1 if x in y else 0 for x,y in zip(df[\"q'\"],df[\"q\"])]\n",
        "df['sub_r_true'] = [1 if x in y else 0 for x,y in zip(df[\"r'\"],df[\"r\"])]\n",
        "df['sub_both'] = df['sub_q_true']*df['sub_r_true']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OK1pkEH7kAwd"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bs3IcEBHo151"
      },
      "outputs": [],
      "source": [
        "# train\n",
        "data = df.loc[df['sub_both'] == 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B3jCjQHmOGHa"
      },
      "outputs": [],
      "source": [
        "# train\n",
        "data['q_start'] = [y.index(x) for x,y in zip(data[\"q'\"],data[\"q\"])]\n",
        "data['r_start'] = [y.index(x) for x,y in zip(data[\"r'\"],data[\"r\"])]\n",
        "data['q_end'] = [x+len(y)-1 for x,y in zip(data[\"q_start\"],data[\"q'\"])]\n",
        "data['r_end'] = [x+len(y)-1 for x,y in zip(data[\"r_start\"],data[\"r'\"])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vj2fwlLGpCJZ"
      },
      "outputs": [],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LCLHjB6BQoDg"
      },
      "outputs": [],
      "source": [
        "# test\n",
        "df_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5iPUrfp5SULR"
      },
      "outputs": [],
      "source": [
        "train = data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wWuilvdGhFkb"
      },
      "outputs": [],
      "source": [
        "# test\n",
        "test = df_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcQn-_Rq5yfT"
      },
      "source": [
        "## Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJNMGgErziHa"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TozH0A1pm2bv"
      },
      "outputs": [],
      "source": [
        "train_data_q = train['q'].tolist()\n",
        "test_data_q = test['q'].tolist()\n",
        "\n",
        "train_data_r = train['r'].tolist()\n",
        "test_data_r = test['r'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4-Xb_k1kfyv"
      },
      "outputs": [],
      "source": [
        "train_encodings = tokenizer(train_data_q, train_data_r, truncation=True, padding=True)\n",
        "test_encodings = tokenizer(test_data_q, test_data_r, truncation=True, padding=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "grCTbJ7pkpfC"
      },
      "outputs": [],
      "source": [
        "tokenizer.decode(train_encodings['input_ids'][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S5t3h8yAS2lb"
      },
      "outputs": [],
      "source": [
        "tokenizer.decode(test_encodings['input_ids'][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CDnrLp0hvvGW"
      },
      "outputs": [],
      "source": [
        "# train\n",
        "train_answer = train[['q_start', 'r_start',\t'q_end', 'r_end']].to_dict('records')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v8oUTnyktl_x"
      },
      "outputs": [],
      "source": [
        "def add_token_positions(encodings, answers):\n",
        "    q_start, r_start, q_end, r_end = [],[],[],[]\n",
        "\n",
        "    for i in range(len(answers)):\n",
        "        q_start.append(encodings.char_to_token(i, answers[i]['q_start'], 0))\n",
        "        r_start.append(encodings.char_to_token(i, answers[i]['r_start'], 1))\n",
        "        q_end.append(encodings.char_to_token(i, answers[i]['q_end'], 0))\n",
        "        r_end.append(encodings.char_to_token(i, answers[i]['r_end'], 1))\n",
        "\n",
        "        if q_start[-1] is None:\n",
        "            q_start[-1] = 0\n",
        "            q_end[-1] = 0\n",
        "            # continue\n",
        "\n",
        "        if r_start[-1] is None:\n",
        "            r_start[-1] = 0\n",
        "            r_end[-1] = 0\n",
        "            # continue\n",
        "\n",
        "        shift = 1\n",
        "        while q_end[-1] is None:\n",
        "            q_end[-1] = encodings.char_to_token(i, answers[i]['q_end'] - shift)\n",
        "            shift += 1\n",
        "        shift = 1\n",
        "        while r_end[-1] is None:\n",
        "            r_end[-1] = encodings.char_to_token(i, answers[i]['r_end'] - shift)\n",
        "            shift += 1\n",
        "    encodings.update({'q_start':q_start, 'r_start':r_start,\t'q_end':q_end, 'r_end':r_end})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1xqKVrBwSHx"
      },
      "outputs": [],
      "source": [
        "# Convert char_based_id to token_based_id\n",
        "# Find the corossponding token id after input being tokenized\n",
        "add_token_positions(train_encodings, train_answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "RZhJSrR7xTjv"
      },
      "outputs": [],
      "source": [
        "train_encodings.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ASGnbhNXRiJ8"
      },
      "outputs": [],
      "source": [
        "test_encodings.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BKGfnJV2JbAF"
      },
      "outputs": [],
      "source": [
        "# print(train_encodings['q_start'][0])\n",
        "# print(train_encodings['r_start'][0])\n",
        "# print(train_encodings['q_end'][0])\n",
        "# print(train_encodings['r_end'][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGfziDMh6iOP"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Awivv8SdNm_d"
      },
      "outputs": [],
      "source": [
        "\n",
        "class qrDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings):\n",
        "        self.encodings = encodings\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings.input_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "yIjnUh9qOEjD"
      },
      "outputs": [],
      "source": [
        "train_dataset = qrDataset(train_encodings)\n",
        "test_dataset = qrDataset(test_encodings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ui3__xvEPcia"
      },
      "outputs": [],
      "source": [
        "next(iter(train_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lZ8pWgExRoNf"
      },
      "outputs": [],
      "source": [
        "next(iter(test_dataset))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anB_LCU16q-C"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rwZdH-I4PoAf"
      },
      "outputs": [],
      "source": [
        "from transformers import BertModel\n",
        "\n",
        "class myModel(torch.nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        super(myModel, self).__init__()\n",
        "\n",
        "        self.bert = BertModel.from_pretrained('bert-base-cased')\n",
        "        self.fc = nn.Linear(768, 4)\n",
        "\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
        "\n",
        "        output = self.bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, return_dict=True)\n",
        "        logits = output[0]\n",
        "        out = self.fc(logits)\n",
        "\n",
        "        return out\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEUJSg7E6wWF"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mIZ50YA8OfgB"
      },
      "outputs": [],
      "source": [
        "from transformers import AdamW\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Set GPU / CPU\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "# Put model on device\n",
        "model = myModel().to(device)\n",
        "\n",
        "optim = AdamW(model.parameters(), lr=1e-6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JIwySrYN9EOp"
      },
      "outputs": [],
      "source": [
        "# Pack data into dataloader by batch\n",
        "batch_size = 8\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aJrCvwVl8A3d"
      },
      "outputs": [],
      "source": [
        "training_epoch = 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5W9Z0_YkYBA0"
      },
      "outputs": [],
      "source": [
        "loss_fct = CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-RIFNMy0WHvk"
      },
      "outputs": [],
      "source": [
        "for epoch in range(training_epoch):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    loop = tqdm(train_loader, leave=True)\n",
        "    for batch_id, batch in enumerate(loop):\n",
        "        # reset\n",
        "        optim.zero_grad()\n",
        "\n",
        "\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        token_type_ids = batch['token_type_ids'].to(device)\n",
        "        q_start = batch['q_start'].to(device)\n",
        "        r_start = batch['r_start'].to(device)\n",
        "        q_end = batch['q_end'].to(device)\n",
        "        r_end = batch['r_end'].to(device)\n",
        "\n",
        "\n",
        "        # model output\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "\n",
        "        q_start_logits, r_start_logits, q_end_logits, r_end_logits = torch.split(outputs, 1, 2)\n",
        "\n",
        "        q_start_logits = q_start_logits.squeeze(-1).contiguous()\n",
        "        r_start_logits = r_start_logits.squeeze(-1).contiguous()\n",
        "        q_end_logits = q_end_logits.squeeze(-1).contiguous()\n",
        "        r_end_logits = r_end_logits.squeeze(-1).contiguous()\n",
        "\n",
        "        q_start_loss = loss_fct(q_start_logits, q_start)\n",
        "        r_start_loss = loss_fct(r_start_logits, r_start)\n",
        "        q_end_loss = loss_fct(q_end_logits, q_end)\n",
        "        r_end_loss = loss_fct(r_end_logits, r_end)\n",
        "\n",
        "\n",
        "\n",
        "        loss = q_start_loss + r_start_loss + q_end_loss + r_end_loss\n",
        "\n",
        "        # calculate loss\n",
        "        loss.backward()\n",
        "        # update parameters\n",
        "        optim.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if batch_id % 200 == 0 and batch_id != 0:\n",
        "            print('Epoch {} Batch {} Loss {:.4f}'.format(\n",
        "                batch_id + 1, batch_id, running_loss / 200))\n",
        "            running_loss = 0.0\n",
        "\n",
        "        loop.set_description(f'Epoch {epoch}')\n",
        "        loop.set_postfix(loss=loss.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58r9NzS-NILH"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), directory + 'aicup_model_4eplr16.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oHM3KS8wNI46"
      },
      "outputs": [],
      "source": [
        "model = myModel().to(device)\n",
        "model.load_state_dict(torch.load(directory + 'aicup_model_4eplr16.pt'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xi-K6PR7s0_"
      },
      "source": [
        "## Predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vjSjODbl312a"
      },
      "outputs": [],
      "source": [
        "def predict(test_loader):\n",
        "    predict_pos = []\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    q_sub_output, r_sub_output = [],[]\n",
        "\n",
        "    loop = tqdm(test_loader, leave=True)\n",
        "    for batch_id, batch in enumerate(loop):\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        token_type_ids = batch['token_type_ids'].to(device)\n",
        "\n",
        "        # model output\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "\n",
        "        q_start_logits, r_start_logits, q_end_logits, r_end_logits = torch.split(outputs, 1, 2)\n",
        "\n",
        "        q_start_logits = q_start_logits.squeeze(-1).contiguous()\n",
        "        r_start_logits = r_start_logits.squeeze(-1).contiguous()\n",
        "        q_end_logits = q_end_logits.squeeze(-1).contiguous()\n",
        "        r_end_logits = r_end_logits.squeeze(-1).contiguous()\n",
        "\n",
        "        q_start_prdict = torch.argmax(q_start_logits, 1).cpu().numpy()\n",
        "        r_start_prdict = torch.argmax(r_start_logits, 1).cpu().numpy()\n",
        "        q_end_prdict = torch.argmax(q_end_logits, 1).cpu().numpy()\n",
        "        r_end_prdict = torch.argmax(r_end_logits, 1).cpu().numpy()\n",
        "\n",
        "        for i in range(len(input_ids)):\n",
        "            predict_pos.append((q_start_prdict[i].item(), r_start_prdict[i].item(), q_end_prdict[i].item(), r_end_prdict[i].item()))\n",
        "\n",
        "            q_sub = tokenizer.decode(input_ids[i][q_start_prdict[i]:q_end_prdict[i]+1])\n",
        "            r_sub = tokenizer.decode(input_ids[i][r_start_prdict[i]:r_end_prdict[i]+1])\n",
        "\n",
        "            q_sub_output.append(q_sub)\n",
        "            r_sub_output.append(r_sub)\n",
        "\n",
        "    return q_sub_output, r_sub_output, predict_pos\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0N3-L47N84Oh"
      },
      "outputs": [],
      "source": [
        "q_sub_output, r_sub_output, predict_pos = predict(test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vIXjyoo3Sgb0"
      },
      "outputs": [],
      "source": [
        "def get_output_post_fn(df_test, q_sub_output, r_sub_output):\n",
        "    q_sub, r_sub = [], []\n",
        "    for i in range(len(test)):\n",
        "\n",
        "        q_sub_pred = q_sub_output[i].split()\n",
        "        r_sub_pred = r_sub_output[i].split()\n",
        "\n",
        "        if q_sub_pred is None:\n",
        "            q_sub_pred = []\n",
        "        q_sub_error_index = q_sub_pred.index('[SEP]') if '[SEP]' in q_sub_pred else -1\n",
        "\n",
        "        if q_sub_error_index != -1:\n",
        "            q_sub_pred = q_sub_pred[:q_sub_error_index]\n",
        "\n",
        "        temp = r_sub_pred.copy()\n",
        "        if r_sub_pred is None:\n",
        "            r_sub_pred = []\n",
        "        else:\n",
        "            for j in range(len(temp)):\n",
        "                if temp[j] == '[SEP]':\n",
        "                    r_sub_pred.remove('[SEP]')\n",
        "                if temp[j] == '[PAD]':\n",
        "                    r_sub_pred.remove('[PAD]')\n",
        "\n",
        "        q_sub.append(\" \".join(q_sub_pred))\n",
        "        r_sub.append(\" \".join(r_sub_pred))\n",
        "\n",
        "    return q_sub, r_sub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CrvZftvBSsen"
      },
      "outputs": [],
      "source": [
        "q_sub, r_sub = get_output_post_fn(df_test, q_sub_output, r_sub_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AtCGRLfO95qW"
      },
      "outputs": [],
      "source": [
        "q = []\n",
        "for i in range(len(q_sub)):\n",
        "  q_ = \"\\\"\" + q_sub[i] + \"\\\"\"\n",
        "  q.append(q_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rbmxdr4j95oN"
      },
      "outputs": [],
      "source": [
        "r = []\n",
        "for i in range(len(r_sub)):\n",
        "  r_ = \"\\\"\" + r_sub[i] + \"\\\"\"\n",
        "  r.append(r_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__Pliyl695l5"
      },
      "outputs": [],
      "source": [
        "data = {\n",
        "    \"id\": df_test[\"id\"],\n",
        "    \"q\": q,\n",
        "    \"r\": r\n",
        "}\n",
        "df_submit = pd.DataFrame(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3xD2Eh05AU86"
      },
      "outputs": [],
      "source": [
        "df_submit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R6OYl2JKAcSu"
      },
      "outputs": [],
      "source": [
        "with open(directory + \"predict_test.4eplr16.csv\", \"w\", encoding=\"utf-8\") as f:\n",
        "  df_submit.to_csv(f, index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}